{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d0ec5e8",
   "metadata": {},
   "source": [
    "### 1. Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a64ac869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8599112",
   "metadata": {},
   "source": [
    "### 2. check cuda available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "380bc4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0189681d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e71024",
   "metadata": {},
   "source": [
    "### 3. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a55d8939",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa884599",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([  transforms.Resize(28),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "train_dataset = datasets.MNIST(root=\"./dataset\", train=True, download=True, transform=train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55a0e36c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c5b5d1",
   "metadata": {},
   "source": [
    "### 4. DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "879ba5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847ac1de",
   "metadata": {},
   "source": [
    "### 5. Model Architecture   \n",
    "\n",
    "- Generator  \n",
    "- Discriminator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06ffe5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25a582b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Linear(start_size, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.layer2 = nn.Linear(256, 512)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.layer3 = nn.Linear(512, 1024)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.layer4 = nn.Linear(1024, 512)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.relu = nn.LeakyReLU(0.1, inplace=True)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.last = nn.Linear(512, 1*28*28)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        z = self.relu(self.layer1(z))\n",
    "        z = self.relu(self.bn2(self.layer2(z)))\n",
    "        z = self.relu(self.bn3(self.layer3(z)))\n",
    "        z = self.relu(self.bn4(self.layer4(z)))\n",
    "        z = self.tanh(self.last(z))\n",
    "        z = z.view(z.size(0), 1, 28, 28)\n",
    "        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95726608",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(1 * 28 * 28, 256),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        flattened = img.view(img.size(0), -1)\n",
    "        output = self.model(flattened)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbcc855",
   "metadata": {},
   "source": [
    "### 6. Loss Function & Optimizer\n",
    "\n",
    "- Generator\n",
    "- Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24eb2871",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "gen_optim = optim.Adam(generator.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
    "dis_optim = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "criterion = nn.BCELoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfbe6c9",
   "metadata": {},
   "source": [
    "### 7. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b237e5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/300] dis_loss: 0.711621, gen_loss: 0.604549\n",
      "[Epoch 1/300] dis_loss: 0.675958, gen_loss: 0.683521\n",
      "[Epoch 2/300] dis_loss: 0.697907, gen_loss: 0.679104\n",
      "[Epoch 3/300] dis_loss: 0.683818, gen_loss: 0.717553\n",
      "[Epoch 4/300] dis_loss: 0.677676, gen_loss: 0.683251\n",
      "[Epoch 5/300] dis_loss: 0.703114, gen_loss: 0.639956\n",
      "[Epoch 6/300] dis_loss: 0.689548, gen_loss: 0.691673\n",
      "[Epoch 7/300] dis_loss: 0.701899, gen_loss: 0.704502\n",
      "[Epoch 8/300] dis_loss: 0.723587, gen_loss: 0.667032\n",
      "[Epoch 9/300] dis_loss: 0.677767, gen_loss: 0.729972\n",
      "[Epoch 10/300] dis_loss: 0.728308, gen_loss: 0.649173\n",
      "[Epoch 11/300] dis_loss: 0.694781, gen_loss: 0.722863\n",
      "[Epoch 12/300] dis_loss: 0.666240, gen_loss: 0.729376\n",
      "[Epoch 13/300] dis_loss: 0.624745, gen_loss: 0.684075\n",
      "[Epoch 14/300] dis_loss: 0.686421, gen_loss: 0.692862\n",
      "[Epoch 15/300] dis_loss: 0.652480, gen_loss: 0.612224\n",
      "[Epoch 16/300] dis_loss: 0.694400, gen_loss: 0.718676\n",
      "[Epoch 17/300] dis_loss: 0.703361, gen_loss: 0.668124\n",
      "[Epoch 18/300] dis_loss: 0.677844, gen_loss: 0.711889\n",
      "[Epoch 19/300] dis_loss: 0.664990, gen_loss: 0.752956\n",
      "[Epoch 20/300] dis_loss: 0.655082, gen_loss: 0.809386\n",
      "[Epoch 21/300] dis_loss: 0.633175, gen_loss: 0.812600\n",
      "[Epoch 22/300] dis_loss: 0.653268, gen_loss: 0.735898\n",
      "[Epoch 23/300] dis_loss: 0.698909, gen_loss: 0.684989\n",
      "[Epoch 24/300] dis_loss: 0.661065, gen_loss: 0.699302\n",
      "[Epoch 25/300] dis_loss: 0.709793, gen_loss: 0.682762\n",
      "[Epoch 26/300] dis_loss: 0.706807, gen_loss: 0.697591\n",
      "[Epoch 27/300] dis_loss: 0.699251, gen_loss: 0.817725\n",
      "[Epoch 28/300] dis_loss: 0.677778, gen_loss: 0.678026\n",
      "[Epoch 29/300] dis_loss: 0.678741, gen_loss: 0.708655\n",
      "[Epoch 30/300] dis_loss: 0.687629, gen_loss: 0.714188\n",
      "[Epoch 31/300] dis_loss: 0.690780, gen_loss: 0.734042\n",
      "[Epoch 32/300] dis_loss: 0.657721, gen_loss: 0.777879\n",
      "[Epoch 33/300] dis_loss: 0.683964, gen_loss: 0.721405\n",
      "[Epoch 34/300] dis_loss: 0.673630, gen_loss: 0.688950\n",
      "[Epoch 35/300] dis_loss: 0.790406, gen_loss: 0.719362\n",
      "[Epoch 36/300] dis_loss: 0.644741, gen_loss: 0.777023\n",
      "[Epoch 37/300] dis_loss: 0.747913, gen_loss: 0.651840\n",
      "[Epoch 38/300] dis_loss: 0.665486, gen_loss: 0.696928\n",
      "[Epoch 39/300] dis_loss: 0.674160, gen_loss: 0.761425\n",
      "[Epoch 40/300] dis_loss: 0.690202, gen_loss: 0.667000\n",
      "[Epoch 41/300] dis_loss: 0.754147, gen_loss: 0.684752\n",
      "[Epoch 42/300] dis_loss: 0.600100, gen_loss: 0.775577\n",
      "[Epoch 43/300] dis_loss: 0.634971, gen_loss: 0.778471\n",
      "[Epoch 44/300] dis_loss: 0.653755, gen_loss: 0.752277\n",
      "[Epoch 45/300] dis_loss: 0.550552, gen_loss: 0.968302\n",
      "[Epoch 46/300] dis_loss: 0.665763, gen_loss: 0.738410\n",
      "[Epoch 47/300] dis_loss: 0.723870, gen_loss: 0.658065\n",
      "[Epoch 48/300] dis_loss: 0.581306, gen_loss: 0.900002\n",
      "[Epoch 49/300] dis_loss: 0.702770, gen_loss: 0.742949\n",
      "[Epoch 50/300] dis_loss: 0.657682, gen_loss: 0.707724\n",
      "[Epoch 51/300] dis_loss: 0.651160, gen_loss: 0.603639\n",
      "[Epoch 52/300] dis_loss: 0.543561, gen_loss: 1.004575\n",
      "[Epoch 53/300] dis_loss: 0.476511, gen_loss: 1.062822\n",
      "[Epoch 54/300] dis_loss: 0.661310, gen_loss: 0.943067\n",
      "[Epoch 55/300] dis_loss: 0.616806, gen_loss: 0.793577\n",
      "[Epoch 56/300] dis_loss: 0.640772, gen_loss: 0.866220\n",
      "[Epoch 57/300] dis_loss: 0.675961, gen_loss: 0.785726\n",
      "[Epoch 58/300] dis_loss: 0.602936, gen_loss: 0.921968\n",
      "[Epoch 59/300] dis_loss: 0.563233, gen_loss: 0.856055\n",
      "[Epoch 60/300] dis_loss: 0.649702, gen_loss: 0.987498\n",
      "[Epoch 61/300] dis_loss: 0.486159, gen_loss: 0.933620\n",
      "[Epoch 62/300] dis_loss: 0.571156, gen_loss: 0.912593\n",
      "[Epoch 63/300] dis_loss: 0.596667, gen_loss: 0.814827\n",
      "[Epoch 64/300] dis_loss: 0.588285, gen_loss: 0.750643\n",
      "[Epoch 65/300] dis_loss: 0.632537, gen_loss: 1.025599\n",
      "[Epoch 66/300] dis_loss: 0.660507, gen_loss: 0.708936\n",
      "[Epoch 67/300] dis_loss: 0.646107, gen_loss: 0.787624\n",
      "[Epoch 68/300] dis_loss: 0.581153, gen_loss: 0.887043\n",
      "[Epoch 69/300] dis_loss: 0.665350, gen_loss: 0.804487\n",
      "[Epoch 70/300] dis_loss: 0.774620, gen_loss: 0.694695\n",
      "[Epoch 71/300] dis_loss: 0.669006, gen_loss: 0.759477\n",
      "[Epoch 72/300] dis_loss: 0.586042, gen_loss: 0.755665\n",
      "[Epoch 73/300] dis_loss: 0.786653, gen_loss: 0.743295\n",
      "[Epoch 74/300] dis_loss: 0.578297, gen_loss: 0.977237\n",
      "[Epoch 75/300] dis_loss: 0.488838, gen_loss: 1.024720\n",
      "[Epoch 76/300] dis_loss: 0.613026, gen_loss: 0.931399\n",
      "[Epoch 77/300] dis_loss: 0.541816, gen_loss: 1.202413\n",
      "[Epoch 78/300] dis_loss: 0.632556, gen_loss: 0.815042\n",
      "[Epoch 79/300] dis_loss: 0.574974, gen_loss: 0.794573\n",
      "[Epoch 80/300] dis_loss: 0.569690, gen_loss: 0.731479\n",
      "[Epoch 81/300] dis_loss: 0.672439, gen_loss: 0.977416\n",
      "[Epoch 82/300] dis_loss: 0.609169, gen_loss: 0.984815\n",
      "[Epoch 83/300] dis_loss: 0.525437, gen_loss: 0.870655\n",
      "[Epoch 84/300] dis_loss: 0.745622, gen_loss: 0.879342\n",
      "[Epoch 85/300] dis_loss: 0.571815, gen_loss: 1.063550\n",
      "[Epoch 86/300] dis_loss: 0.692837, gen_loss: 1.078314\n",
      "[Epoch 87/300] dis_loss: 0.603011, gen_loss: 1.007903\n",
      "[Epoch 88/300] dis_loss: 0.614504, gen_loss: 0.798111\n",
      "[Epoch 89/300] dis_loss: 0.548152, gen_loss: 1.149504\n",
      "[Epoch 90/300] dis_loss: 0.559921, gen_loss: 1.353869\n",
      "[Epoch 91/300] dis_loss: 0.650036, gen_loss: 0.776801\n",
      "[Epoch 92/300] dis_loss: 0.561880, gen_loss: 0.949748\n",
      "[Epoch 93/300] dis_loss: 0.618619, gen_loss: 0.895320\n",
      "[Epoch 94/300] dis_loss: 0.588510, gen_loss: 1.071425\n",
      "[Epoch 95/300] dis_loss: 0.643626, gen_loss: 0.711713\n",
      "[Epoch 96/300] dis_loss: 0.535093, gen_loss: 1.126358\n",
      "[Epoch 97/300] dis_loss: 0.489587, gen_loss: 1.064318\n",
      "[Epoch 98/300] dis_loss: 0.587895, gen_loss: 0.899704\n",
      "[Epoch 99/300] dis_loss: 0.577515, gen_loss: 1.067764\n",
      "[Epoch 100/300] dis_loss: 0.670607, gen_loss: 0.769431\n",
      "[Epoch 101/300] dis_loss: 0.635628, gen_loss: 0.645856\n",
      "[Epoch 102/300] dis_loss: 0.650373, gen_loss: 0.804369\n",
      "[Epoch 103/300] dis_loss: 0.622371, gen_loss: 1.002498\n",
      "[Epoch 104/300] dis_loss: 0.640771, gen_loss: 0.759699\n",
      "[Epoch 105/300] dis_loss: 0.666461, gen_loss: 1.025699\n",
      "[Epoch 106/300] dis_loss: 0.585276, gen_loss: 0.997179\n",
      "[Epoch 107/300] dis_loss: 0.642049, gen_loss: 0.999856\n",
      "[Epoch 108/300] dis_loss: 0.478138, gen_loss: 1.180596\n",
      "[Epoch 109/300] dis_loss: 0.572443, gen_loss: 0.938853\n",
      "[Epoch 110/300] dis_loss: 0.520166, gen_loss: 1.166880\n",
      "[Epoch 111/300] dis_loss: 0.621244, gen_loss: 1.225206\n",
      "[Epoch 112/300] dis_loss: 0.414115, gen_loss: 1.267861\n",
      "[Epoch 113/300] dis_loss: 0.544597, gen_loss: 1.163053\n",
      "[Epoch 114/300] dis_loss: 0.545859, gen_loss: 1.305797\n",
      "[Epoch 115/300] dis_loss: 0.470278, gen_loss: 1.225902\n",
      "[Epoch 116/300] dis_loss: 0.587084, gen_loss: 0.745095\n",
      "[Epoch 117/300] dis_loss: 0.484486, gen_loss: 1.037789\n",
      "[Epoch 118/300] dis_loss: 0.471831, gen_loss: 1.216401\n",
      "[Epoch 119/300] dis_loss: 0.595483, gen_loss: 0.792987\n",
      "[Epoch 120/300] dis_loss: 0.471784, gen_loss: 1.283739\n",
      "[Epoch 121/300] dis_loss: 0.584711, gen_loss: 0.837039\n",
      "[Epoch 122/300] dis_loss: 0.513615, gen_loss: 0.902274\n",
      "[Epoch 123/300] dis_loss: 0.692878, gen_loss: 0.713238\n",
      "[Epoch 124/300] dis_loss: 0.605921, gen_loss: 1.035405\n",
      "[Epoch 125/300] dis_loss: 0.518756, gen_loss: 0.844859\n",
      "[Epoch 126/300] dis_loss: 0.443774, gen_loss: 1.136717\n",
      "[Epoch 127/300] dis_loss: 0.513957, gen_loss: 1.426168\n",
      "[Epoch 128/300] dis_loss: 0.547295, gen_loss: 1.140128\n",
      "[Epoch 129/300] dis_loss: 0.511267, gen_loss: 1.222834\n",
      "[Epoch 130/300] dis_loss: 0.603457, gen_loss: 1.018688\n",
      "[Epoch 131/300] dis_loss: 0.519287, gen_loss: 0.972323\n",
      "[Epoch 132/300] dis_loss: 0.591438, gen_loss: 0.788203\n",
      "[Epoch 133/300] dis_loss: 0.428383, gen_loss: 1.208515\n",
      "[Epoch 134/300] dis_loss: 0.482126, gen_loss: 0.822671\n",
      "[Epoch 135/300] dis_loss: 0.659376, gen_loss: 1.298704\n",
      "[Epoch 136/300] dis_loss: 0.560312, gen_loss: 1.202978\n",
      "[Epoch 137/300] dis_loss: 0.489914, gen_loss: 1.197472\n",
      "[Epoch 138/300] dis_loss: 0.540785, gen_loss: 1.506531\n",
      "[Epoch 139/300] dis_loss: 0.514033, gen_loss: 1.109755\n",
      "[Epoch 140/300] dis_loss: 0.588325, gen_loss: 0.994496\n",
      "[Epoch 141/300] dis_loss: 0.669610, gen_loss: 1.496929\n",
      "[Epoch 142/300] dis_loss: 0.490285, gen_loss: 1.157389\n",
      "[Epoch 143/300] dis_loss: 0.532966, gen_loss: 1.029186\n",
      "[Epoch 144/300] dis_loss: 0.491497, gen_loss: 0.967954\n",
      "[Epoch 145/300] dis_loss: 0.573416, gen_loss: 0.756877\n",
      "[Epoch 146/300] dis_loss: 0.429662, gen_loss: 1.172785\n",
      "[Epoch 147/300] dis_loss: 0.509904, gen_loss: 1.617008\n",
      "[Epoch 148/300] dis_loss: 0.747441, gen_loss: 0.804639\n",
      "[Epoch 149/300] dis_loss: 0.604444, gen_loss: 0.860762\n",
      "[Epoch 150/300] dis_loss: 0.430946, gen_loss: 1.141767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 151/300] dis_loss: 0.517857, gen_loss: 0.904596\n",
      "[Epoch 152/300] dis_loss: 0.484985, gen_loss: 1.024709\n",
      "[Epoch 153/300] dis_loss: 0.463480, gen_loss: 1.065097\n",
      "[Epoch 154/300] dis_loss: 0.548621, gen_loss: 0.903532\n",
      "[Epoch 155/300] dis_loss: 0.436405, gen_loss: 1.116523\n",
      "[Epoch 156/300] dis_loss: 0.365415, gen_loss: 1.548401\n",
      "[Epoch 157/300] dis_loss: 0.525627, gen_loss: 1.107382\n",
      "[Epoch 158/300] dis_loss: 0.556611, gen_loss: 1.107062\n",
      "[Epoch 159/300] dis_loss: 0.471915, gen_loss: 1.342646\n",
      "[Epoch 160/300] dis_loss: 0.407337, gen_loss: 1.225633\n",
      "[Epoch 161/300] dis_loss: 0.646965, gen_loss: 0.961939\n",
      "[Epoch 162/300] dis_loss: 0.459261, gen_loss: 1.231954\n",
      "[Epoch 163/300] dis_loss: 0.614931, gen_loss: 0.798365\n",
      "[Epoch 164/300] dis_loss: 0.575346, gen_loss: 1.316073\n",
      "[Epoch 165/300] dis_loss: 0.447005, gen_loss: 1.146598\n",
      "[Epoch 166/300] dis_loss: 0.410609, gen_loss: 1.109665\n",
      "[Epoch 167/300] dis_loss: 0.588000, gen_loss: 1.343824\n",
      "[Epoch 168/300] dis_loss: 0.502433, gen_loss: 0.857594\n",
      "[Epoch 169/300] dis_loss: 0.474749, gen_loss: 1.226618\n",
      "[Epoch 170/300] dis_loss: 0.462860, gen_loss: 1.239351\n",
      "[Epoch 171/300] dis_loss: 0.306243, gen_loss: 1.515843\n",
      "[Epoch 172/300] dis_loss: 0.338493, gen_loss: 1.266162\n",
      "[Epoch 173/300] dis_loss: 0.436854, gen_loss: 1.001478\n",
      "[Epoch 174/300] dis_loss: 0.572819, gen_loss: 1.870660\n",
      "[Epoch 175/300] dis_loss: 0.505621, gen_loss: 1.760563\n",
      "[Epoch 176/300] dis_loss: 0.484885, gen_loss: 1.042191\n",
      "[Epoch 177/300] dis_loss: 0.416670, gen_loss: 1.130239\n",
      "[Epoch 178/300] dis_loss: 0.338906, gen_loss: 1.716627\n",
      "[Epoch 179/300] dis_loss: 0.511995, gen_loss: 1.269209\n",
      "[Epoch 180/300] dis_loss: 0.409560, gen_loss: 1.695965\n",
      "[Epoch 181/300] dis_loss: 0.612264, gen_loss: 1.127779\n",
      "[Epoch 182/300] dis_loss: 0.582121, gen_loss: 0.618744\n",
      "[Epoch 183/300] dis_loss: 0.399440, gen_loss: 1.400630\n",
      "[Epoch 184/300] dis_loss: 0.538545, gen_loss: 1.079169\n",
      "[Epoch 185/300] dis_loss: 0.410259, gen_loss: 1.235409\n",
      "[Epoch 186/300] dis_loss: 0.437195, gen_loss: 1.374369\n",
      "[Epoch 187/300] dis_loss: 0.348067, gen_loss: 1.172110\n",
      "[Epoch 188/300] dis_loss: 0.399864, gen_loss: 1.607239\n",
      "[Epoch 189/300] dis_loss: 0.601314, gen_loss: 0.934918\n",
      "[Epoch 190/300] dis_loss: 0.432573, gen_loss: 1.411628\n",
      "[Epoch 191/300] dis_loss: 0.494275, gen_loss: 0.976347\n",
      "[Epoch 192/300] dis_loss: 0.401564, gen_loss: 1.461235\n",
      "[Epoch 193/300] dis_loss: 0.473221, gen_loss: 1.379771\n",
      "[Epoch 194/300] dis_loss: 0.437957, gen_loss: 1.441986\n",
      "[Epoch 195/300] dis_loss: 0.439068, gen_loss: 1.260885\n",
      "[Epoch 196/300] dis_loss: 0.514540, gen_loss: 0.885225\n",
      "[Epoch 197/300] dis_loss: 0.537999, gen_loss: 1.286418\n",
      "[Epoch 198/300] dis_loss: 0.435587, gen_loss: 1.020373\n",
      "[Epoch 199/300] dis_loss: 0.466413, gen_loss: 1.306272\n",
      "[Epoch 200/300] dis_loss: 0.620890, gen_loss: 1.264988\n",
      "[Epoch 201/300] dis_loss: 0.461020, gen_loss: 1.605976\n",
      "[Epoch 202/300] dis_loss: 0.487205, gen_loss: 2.138366\n",
      "[Epoch 203/300] dis_loss: 0.431244, gen_loss: 1.429092\n",
      "[Epoch 204/300] dis_loss: 0.544059, gen_loss: 1.273855\n",
      "[Epoch 205/300] dis_loss: 0.357123, gen_loss: 1.394172\n",
      "[Epoch 206/300] dis_loss: 0.467921, gen_loss: 1.356988\n",
      "[Epoch 207/300] dis_loss: 0.817405, gen_loss: 1.773299\n",
      "[Epoch 208/300] dis_loss: 0.376982, gen_loss: 1.206803\n",
      "[Epoch 209/300] dis_loss: 0.430890, gen_loss: 1.604001\n",
      "[Epoch 210/300] dis_loss: 0.470515, gen_loss: 1.262426\n",
      "[Epoch 211/300] dis_loss: 0.411018, gen_loss: 1.218852\n",
      "[Epoch 212/300] dis_loss: 0.659220, gen_loss: 1.724867\n",
      "[Epoch 213/300] dis_loss: 0.478834, gen_loss: 1.063272\n",
      "[Epoch 214/300] dis_loss: 0.471683, gen_loss: 0.909440\n",
      "[Epoch 215/300] dis_loss: 0.466276, gen_loss: 1.293202\n",
      "[Epoch 216/300] dis_loss: 0.525648, gen_loss: 1.024657\n",
      "[Epoch 217/300] dis_loss: 0.767497, gen_loss: 0.522323\n",
      "[Epoch 218/300] dis_loss: 0.443169, gen_loss: 1.703754\n",
      "[Epoch 219/300] dis_loss: 0.435364, gen_loss: 1.569207\n",
      "[Epoch 220/300] dis_loss: 0.547887, gen_loss: 1.213948\n",
      "[Epoch 221/300] dis_loss: 0.548113, gen_loss: 0.651889\n",
      "[Epoch 222/300] dis_loss: 0.473582, gen_loss: 1.498795\n",
      "[Epoch 223/300] dis_loss: 0.384248, gen_loss: 1.503564\n",
      "[Epoch 224/300] dis_loss: 0.583096, gen_loss: 0.833548\n",
      "[Epoch 225/300] dis_loss: 0.491764, gen_loss: 1.210209\n",
      "[Epoch 226/300] dis_loss: 0.432949, gen_loss: 1.268278\n",
      "[Epoch 227/300] dis_loss: 0.409174, gen_loss: 1.738922\n",
      "[Epoch 228/300] dis_loss: 0.472607, gen_loss: 1.033064\n",
      "[Epoch 229/300] dis_loss: 0.571287, gen_loss: 1.083313\n",
      "[Epoch 230/300] dis_loss: 0.546594, gen_loss: 1.205366\n",
      "[Epoch 231/300] dis_loss: 0.570633, gen_loss: 1.238719\n",
      "[Epoch 232/300] dis_loss: 0.497370, gen_loss: 1.228776\n",
      "[Epoch 233/300] dis_loss: 0.358384, gen_loss: 1.188066\n",
      "[Epoch 234/300] dis_loss: 0.384665, gen_loss: 1.670675\n",
      "[Epoch 235/300] dis_loss: 0.426574, gen_loss: 1.419974\n",
      "[Epoch 236/300] dis_loss: 0.519655, gen_loss: 1.733536\n",
      "[Epoch 237/300] dis_loss: 0.540724, gen_loss: 1.367914\n",
      "[Epoch 238/300] dis_loss: 0.444813, gen_loss: 1.149265\n",
      "[Epoch 239/300] dis_loss: 0.489312, gen_loss: 1.619184\n",
      "[Epoch 240/300] dis_loss: 0.471306, gen_loss: 1.842020\n",
      "[Epoch 241/300] dis_loss: 0.645685, gen_loss: 0.633367\n",
      "[Epoch 242/300] dis_loss: 0.692192, gen_loss: 1.391020\n",
      "[Epoch 243/300] dis_loss: 0.591656, gen_loss: 0.918050\n",
      "[Epoch 244/300] dis_loss: 0.433851, gen_loss: 1.468817\n",
      "[Epoch 245/300] dis_loss: 0.554559, gen_loss: 1.398171\n",
      "[Epoch 246/300] dis_loss: 0.350798, gen_loss: 1.531461\n",
      "[Epoch 247/300] dis_loss: 0.452037, gen_loss: 1.172503\n",
      "[Epoch 248/300] dis_loss: 0.453023, gen_loss: 1.154146\n",
      "[Epoch 249/300] dis_loss: 0.423639, gen_loss: 1.359808\n",
      "[Epoch 250/300] dis_loss: 0.516711, gen_loss: 1.311165\n",
      "[Epoch 251/300] dis_loss: 0.354345, gen_loss: 1.306730\n",
      "[Epoch 252/300] dis_loss: 0.742013, gen_loss: 0.520215\n",
      "[Epoch 253/300] dis_loss: 0.510843, gen_loss: 1.168438\n",
      "[Epoch 254/300] dis_loss: 0.510301, gen_loss: 1.252584\n",
      "[Epoch 255/300] dis_loss: 0.500955, gen_loss: 1.014034\n",
      "[Epoch 256/300] dis_loss: 0.436567, gen_loss: 1.595837\n",
      "[Epoch 257/300] dis_loss: 0.413784, gen_loss: 1.271226\n",
      "[Epoch 258/300] dis_loss: 0.458627, gen_loss: 1.328355\n",
      "[Epoch 259/300] dis_loss: 0.570627, gen_loss: 1.772987\n",
      "[Epoch 260/300] dis_loss: 0.594281, gen_loss: 0.840271\n",
      "[Epoch 261/300] dis_loss: 0.635312, gen_loss: 0.579223\n",
      "[Epoch 262/300] dis_loss: 0.404104, gen_loss: 1.341297\n",
      "[Epoch 263/300] dis_loss: 0.460825, gen_loss: 1.000593\n",
      "[Epoch 264/300] dis_loss: 0.463016, gen_loss: 0.976139\n",
      "[Epoch 265/300] dis_loss: 0.395370, gen_loss: 1.313461\n",
      "[Epoch 266/300] dis_loss: 0.565113, gen_loss: 0.782912\n",
      "[Epoch 267/300] dis_loss: 0.412704, gen_loss: 1.187352\n",
      "[Epoch 268/300] dis_loss: 0.487271, gen_loss: 0.815354\n",
      "[Epoch 269/300] dis_loss: 0.762615, gen_loss: 0.945141\n",
      "[Epoch 270/300] dis_loss: 0.542818, gen_loss: 1.048034\n",
      "[Epoch 271/300] dis_loss: 0.509917, gen_loss: 1.100234\n",
      "[Epoch 272/300] dis_loss: 0.570621, gen_loss: 0.927118\n",
      "[Epoch 273/300] dis_loss: 0.489204, gen_loss: 1.146269\n",
      "[Epoch 274/300] dis_loss: 0.406698, gen_loss: 1.542798\n",
      "[Epoch 275/300] dis_loss: 0.512417, gen_loss: 0.979759\n",
      "[Epoch 276/300] dis_loss: 0.416450, gen_loss: 1.223940\n",
      "[Epoch 277/300] dis_loss: 0.476792, gen_loss: 1.213120\n",
      "[Epoch 278/300] dis_loss: 0.509403, gen_loss: 1.431058\n",
      "[Epoch 279/300] dis_loss: 0.485141, gen_loss: 1.337210\n",
      "[Epoch 280/300] dis_loss: 0.448132, gen_loss: 1.328204\n",
      "[Epoch 281/300] dis_loss: 0.574769, gen_loss: 1.373738\n",
      "[Epoch 282/300] dis_loss: 0.517260, gen_loss: 2.024465\n",
      "[Epoch 283/300] dis_loss: 0.456994, gen_loss: 1.143299\n",
      "[Epoch 284/300] dis_loss: 0.299374, gen_loss: 1.596433\n",
      "[Epoch 285/300] dis_loss: 0.395604, gen_loss: 1.378440\n",
      "[Epoch 286/300] dis_loss: 0.330232, gen_loss: 1.330114\n",
      "[Epoch 287/300] dis_loss: 0.381192, gen_loss: 1.348312\n",
      "[Epoch 288/300] dis_loss: 0.462022, gen_loss: 1.464713\n",
      "[Epoch 289/300] dis_loss: 0.477597, gen_loss: 1.241738\n",
      "[Epoch 290/300] dis_loss: 0.693058, gen_loss: 1.014600\n",
      "[Epoch 291/300] dis_loss: 0.426387, gen_loss: 1.307624\n",
      "[Epoch 292/300] dis_loss: 0.569121, gen_loss: 2.464068\n",
      "[Epoch 293/300] dis_loss: 0.344630, gen_loss: 1.505872\n",
      "[Epoch 294/300] dis_loss: 0.427310, gen_loss: 1.525876\n",
      "[Epoch 295/300] dis_loss: 0.471490, gen_loss: 1.410388\n",
      "[Epoch 296/300] dis_loss: 0.523384, gen_loss: 1.068920\n",
      "[Epoch 297/300] dis_loss: 0.441537, gen_loss: 1.100829\n",
      "[Epoch 298/300] dis_loss: 0.514238, gen_loss: 1.274798\n",
      "[Epoch 299/300] dis_loss: 0.513816, gen_loss: 1.942834\n"
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "\n",
    "for e in range(epochs):\n",
    "    for i, (imgs, l) in enumerate(train_loader):\n",
    "        real = torch.cuda.FloatTensor(imgs.size(0), 1).fill_(1.0)\n",
    "        fake = torch.cuda.FloatTensor(imgs.size(0), 1).fill_(0.0)\n",
    "        \n",
    "        real_imgs = imgs.to(device)\n",
    "        \n",
    "        # train generator\n",
    "        gen_optim.zero_grad()\n",
    "        \n",
    "        z = torch.normal(mean=0, std=1, size=(imgs.shape[0], start_size)).to(device)\n",
    "        \n",
    "        fake_imgs = generator(z)\n",
    "        \n",
    "        gen_loss = criterion(discriminator(fake_imgs), real)\n",
    "        \n",
    "        gen_loss.backward()\n",
    "        gen_optim.step()\n",
    "        \n",
    "        # train discriminator\n",
    "        dis_optim.zero_grad()\n",
    "\n",
    "        real_logits = criterion(discriminator(real_imgs), real)\n",
    "        fake_logits = criterion(discriminator(fake_imgs.detach()), fake)\n",
    "\n",
    "        dis_loss = (real_logits + fake_logits) / 2\n",
    "\n",
    "        dis_loss.backward()\n",
    "        dis_optim.step()\n",
    "        \n",
    "        done = e * len(train_loader) + i\n",
    "        if e%50 == 0:\n",
    "            save_image(fake_imgs.data[:25], f\"generate_img/{done}.png\", nrow=5, normalize=True)\n",
    "            Image(f\"generate_img/{done}.png\")\n",
    "        \n",
    "    print(f\"[Epoch {e}/{epochs}] dis_loss: {dis_loss.item():.6f}, gen_loss: {gen_loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8955c229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJgAAACYCAIAAACXoLd2AAAW70lEQVR4nO1de2xURRef2d2221IebaEFW6BAwRgFgimCgA9IEBApIKAJ8gpixCABIhKJkhCUP5QQEeMHPsBHEAWjwQSBSFAJb5KC0BRtESiUR3mWQt+7e8/3x/l6vmHu3e3eO3Ox6P390dyd7v2ds2feM+fMMObBgwcPHjx48ODBwz8RDzzwwF2QAk1w/G4kEsFnSm9sbNSm3z8AhmEAwNKlS+fOnTtp0iTGmM/n08KMRgcTbDFwzt9++22JoaGhwVmZ+KchOTmZMcY5HzFiBJrG7/eTmdatW6dFSklJiUouoobbtm0DgPnz59Pr+JCamhoIBLToiXCvZLhY5jjn+BcAVq1aJRqacx4OhzXKUsnI5cuXA8DVq1cNwzAT4q/Qq6GY6BKzTiQmJpoTfT4fioyzaV20aFHsL0h2afb3tGnTxlIlMRcltuzs7HhUja1ktIxUtH405srKytTUVBVmxhjjnEcryCSyoKBAUcrGjRvNtI5NIymspZjTu9GoHJNTJdHOHAuzZs2SpAJAOBz2+/2OOS0romPtsYUoLCzEj1evXtWSkWYNzekuMbuCVq1aSVK1FHZi0MKJLx44cABnIExHuyeRmxO1ZGRFRYWUmJ+fr0gr4/vvv8eHGTNm4AwEAFasWMEYKy0tdUxrLhCKuYjtalpaGjJwzn0+n2EYKm0GIRwOR1NMUe0YzEy9oPTs2RMfcLyKOHToEABs3LhRyyDQMv9UlN67dy9j7Pr16yD0aoqckrbmRPrX6dOnNTLjqM12ETFnTFZWFj37/f5AIIDVX1czderUKV0VkZCSkoKjaJzppqWlMZOZVBrtaE1rC2UOBoOZmZlS1oZCIcbY5cuXLV9xVkHF6qIrLxljSUlJABCJRJCwpqYGHwzDME9O4oc0YxbVVlR48uTJmpmTkpJqamrwl9PQhjVN0RhjDQ0N7M4CsmnTJsMwLOeazULKQl15Sb14YmIi5zwYDGJzYsmv2H3qap/0M/fu3fvGjRuGYUgFMC0trXXr1kwYu6pDe11kjPXs2TMalV5BIqdGQm3MRUVFBw8eBACsfISqqirREEePHsX069evO9NSVFejiWOvNJEUn8+ncbymzqOZubGxEQDOnDkDAKFQKCMjQxu1icfcrirSTp069dChQ1euXGFuTvjMhG5kpAbmoqIiAFizZg1ZZPDgwdGoc3Jy8EEc4tpSVKMtjhw5QoUjhkR1QRKtXkJtzABA81O/3z9gwIBAIEBTyQsXLohfdtw6ac9F1jTlIKBukqCUlBRSQPEnMDfbVTQ4U1GPNLtx44aYKCmNAx9FiA2sOhuzquggzEPwOxo2E0zidBG6y3zq1KmTJ08CwH333aeTlzHmTtNkzsusrCxd+5FmQdppiVw/KU45JkyYoJ/aNTib2trCPZaLTK0j+afiLrSrv/32m3ZyDzLuverowYMHDx48ePDwbwLn3NmOh4cWB2983KIQdd/uvffewwfLDOOcl5WVuaQTyb2X1jDvLZBHpEug1XMJWpgtoc58D8C8UAlWYRUa4Z6t3WDWWA4slz8feeSR2F9wiLtWil2qNDk5ObqY9aqXk5OD7mF1dXV+v/+TTz5hJiPU1NSoC2KMsVatWqmrvmHDhthfEMltievevbtLzJZUlhn51VdfOfYjJBiGMX78+Pbt24vpI0eODIVCGtrCYDCIjLjP7HaldKlGmsltvYihvix6ObBLiPM32vHGqDdyGxOzFgCOHz+uwRREumXLFgBYtmxZtG+q+ChLsrTn4q+//qqF3KUSVl9fL0mhB/LRVRIwadIkZNm6dSum6DoxgCCaRm9GusEMAJcuXZISO3bsqKJnSkpKtLB4zMXExERUu7Ky0qEM9I4Uf7neHWaIDkXmFStWaGeOfaiEA3LO+aFDh2KYFDnbtm3LmkI2nOCzzz5DruXLl1t+ob6+fvPmzQ7ZGWMuRGPFYM7Ly1Nktswq9MdXKSXSWz169LBMdw7O+datW7dv3z5lyhTpXxcvXiRh4oDKbjSB9oroKnM0HhC6NLucwWBw4sSJUuLu3bvr6urgztGDXeY79KPwD6nGqKguiRD/asxLN5ilsyTM1tCI6dOnDx06VA/X7t27yS8Zg/FTUlLQCbh9+/Z5eXn19fXjxo1TcVYDq5GIrtrjErOlIMcwd5CNjY1o9vT0dJ0KA8CePXvatGljGAa69pJRAoFAUlKSIjnTXRfdZjYL0s4/a9YsMDn1a8PMmTPxgVQfOnTouHHjnLGJjbMbddEN5mji9JLTKoFIe+rUKQ3UuNY3YMAAKbjCMaHIoNHWNFnSzhwN2vl9Ph8tpenivAOff/55ampqamrqm2++qUUMmKCu5OzZs0VCnPa5mpHMhTVLVHjbtm16aaNKolNsVEh0GVocMkjMrm69Ma0Zies7qPbdcO3v0KGDroAmsRlU5KFnnONC09zp7uyhamG7du3aXWhC/g8AkCKZVdDs9lYLhy6ja+9oPNiARotTFlKIq+uYO3fu3RDT4kGm//rrrzUSut2pe5Cht954zakHDx48ePib4d5EW3H/wIOHfxNwZF9RUaF4FiS6QIi+UjQJUVyz9NA8jhw5gqtfUvrOnTvtUqEDKh6fNWzYMMrFtWvX4hcSEhKYN5dQAdoON9rE9K1bt2ZkZBQXFzs2LlhtiuldUUMS8uOijvzfXsu3bNnCmk42nzp1arPfN4+AxMaTc47+paFQCACGDh1K+ffXX39FW4jJzMxkgot6NACA3++XNuBIVrOax4V33333jTfeEFMSEhK0HNdvidraWjIo5oRd1NXVMasOTF03JKE8a9u2LVm8X79+Ksyc8127dgHAmDFjpOqenp6uwdoAcO7cOXQ78Pl8aCPSHvds6c4sZyKGDx/OOUffLak8OltvjHYHjzP1RNrWrVuLLva0Zf3nn3926tRJhfzFF18EgLKyMsv7vFSYZS4AOHr06MqVK7F0UOKgQYN8Pl/Hjh1jXLtkidzc3IaGBsMwampqKisru3TpgrubpaWlp0+fBoDnnntOY8cDcd/eZUY0B0GxwNnamu3QoYOUgofFm/tCEoFu5rYBAK1btyaWGPdMAUD//v0ff/zxOJmDwSBjbPDgwTt27AiHwxh8RCYuKyvDcUpubi40Hczp5AeYVNW+KyQZoaioSH2RwY37vP4Pn89XXFwsCaCHqVOnqkjas2dPNGb13yDZura2NjEx0bJ6ma+8i41wOIwDYKqRwWDw3Llz5m/27ds3Tk7DMPDmS/yI16HoCcJCRDu+PRQKLVy4EJ0EHAjjTbD8LxJWV1eTpeyqvWHDBqko6Nrh+/HHH0VmrOvRQrFs3TuKhKtWraL7gzXkIpqYojsscevWLbrJJTc31xZ57E4FfwByStccxAnpvGSmbzZWWloqMk+fPl1jo52RkUHlAyc8uLagAZs2bbJMV9deZPD5fOK1corM5HkVjapz587NxjhYDo6+/PJLkTk/P98cKNksiSVWr17NGDt8+LDYvzAd1ogFyUYOhI0ZM0YK0EUe7Bso5cSJEw7UCwQCUu/i8/nw8r6BAweSLAf19amnnqJ2dffu3ZFI5Jlnnrl9+zYTfF+cGYcmi5zzSCQixmXYpYoXn376qfoN4jR3lPDtt99Sxyn2oLYmD+LvF/szesA1FPp+/HtPyHDr1i0QQOkffPBBbW0tAGRmZuJKrGEYr732WvyaY49LpRDD6gAgEonoXKhDMXPmzJHGEXbh8/kaGxvHjh0rMov3bUnMdqeAAFBeXi7aOhKJTJgwAQB27Njx8ccfm/Vv9sYSyyULCZQBjqsRMbRp04Zznp6eHuM+L9UDAJCRRlbOYLnsFAwGFy5cqHi4Fue8qKiIYifEUY9kccbY0qVLY+gjQXQdloxrmcIYw+l4nJq/+uqr0b5smZFKoMpOo/n27ds7EyDdOGsZpKFS6DjnNOoR/fCZqe+JUwqWiW7duuHrWFeKioqIkO6AZ0IwejzMqEAgEIihCTGLSygOMWjQoKefflpz0WCMNXWH2pmh6drI+vp6scZwzocPH2435CE5OZlz/thjj7Hm2ljK6TiZV65cWVdXh72gpQVEy+jxU9Fua1r70N56dOnSRaS9ffs2Pthdx5GAJ4ARm4QlS5bg17p27criNjqGgrOYuajNMj///DNrij7Uw9gEsTo+//zzesmRXwyg16I/DiOxr8VLxMzMMfJGAp2hQw0GEwY+CNX7vGiXyixJF7p06aK9Ot4dnDlzJtq/HIy0zZDWp3DLwTmkXNRr7q5du7rEbEZ6erqr/AjFi++kiqjYEfwPgUBA2oBkutcXMjMzsbm+e/FHbkJLW6XlDsCooMJSWlqqlxlpYzRT9y5a3G1i7kV5mVdc3YNLZrXrHeHhb4CXQx48ePDwT4I23wAPHjxoA60PoHuU9kPIPeiBNCrGDRPMLc45nas3fvx4TMEHAHDS8CIXTiUBgPZgW/hCjEszB7QGni0uWoCOJ3ZAyO5ca2WmpVfV8A+kWLVqleVirhJ1dDg/RV9AcnIyxQClpqZqyVQA8Pl8L730kmQN3P2IkwQ1EeOz2rRpAzERgy2a17GF1A8//BAAOnbsKBWWrKws7cMqXG7F/dWzZ88CgN3j0RHYImVnZ9+6dYt8A9SvJOKc79+/HwDGjh0rWaNDhw52K00gEMA8yMrKQjdzyrPCwkLRvysaQ8+ePeMV1qdPHwBYuHChuJBGAnS1XcQDJqcpB2zi65xzujoIEQwGcYvfgfLoi3zhwgXLmCnH1kBHBXFnZtmyZUpGsNzlAYDa2lpzIkJlY4iahby8PMkKt2/fpgbHLi3phuamZoPS4/TASEtLk1IwwMi87EzM5ldiI9oQFO6ELU4b0CXDXIQxBUPI7IrYt28fuUU1NjZKDZ2os6KDqLsxU4z169dPykg9OxbYfJ89exY/khedG4VFCl5BOLi/AGuhdA4va3LIx82K4cOHO9AwEolwzr/55hv8eODAAdAaM3X+/HlpG7+iosKSmVzmbQCJamtrqWi4W+Wt/B7sMpgHYmggyl3H91ugMvPmzaPoIl3WkH5vUlJSDOZmzyWQgb98xowZ0BQl5Pf7DcPQu8Qgso0ePRp/ALqoHD58WKMgLZvv6EjHdMdMrV+//vLly5RztmY1zePq1ausqUXFFNDk8CH2VZhz2NwBgEu+Duo6L1q0iDG2c+dO7dZ45ZVXmFC5hwwZornNS0tLQ0e8hISESCSC541IVd6BSL/ff/PmTSkRAPCKRyWN78SCBQuIXGTGECq7oJYDKyJ6RqlbgzHWo0cPqTdJTEwsKSkRb6oFgH379pECTgRJqw/nz5/HBwqisAW/35+fn4+3zxImT57MGPvuu+8sX7EV+iuhsLBQHDs45iFIMVO0IhoOh50NiWmAU1lZKfWUOG3dtm0bBhymp6d37tyZMRYKhcQoKHtiAADd5n0+X4woodjul4FAAGPKV65cSYl+vx9NgANXkTAvL+/ixYuOp9uo3sGDB0lVbFRUQFnYrl07znmnTp0SEhKiWaPZwQR+AUyQ/CIl8r59+9quQidOnIj2jqXqzWLKlCk3b97cuHGjlI65pceTs2k+iti7dy8ADBs2DD8WFBQ4ph03bpxeazCTU7k4nzHnIv7FO5LjFZCUlITX+8QYrJMAXDyMp+oEAoGCggKamyL2798vOlYTz5AhQ+JVNwr8fn9jY+Ojjz5KbZEzc6NKsdepRf3jb0XMuYXTd/pXamoqPdA2lA3VL1y40NDQEGeUUDwTkszMzDNnzvh8vl27dplrnjP7xoBhGLTEox7xO3/+/KqqKnPjT3CsP2UhTjkikUh9fb204irCvGjaDKqqqiCKDzjFAjpQ/eTJk/SMayWsuXapXbt2dqVQhcjNzRX7RQD46aef7LIxxnBBn2mKmRIXZsePHx8tz6SayjnHiYq9QYM0osFYe4mdlhjoN8SeHeNGyhdffIEf6cAdZCsvL7ehXxRUVVVJKkUikfiP54qGeGKm6DgCEh2/xfPz8zGaE+6M8JLKB320V4Usi4Z0D7qtVR7qGsXph1ldFZSUlJh1Li8vV19nsLSGFDMVz+JZjM1LzjmOgekMIwlKx6aL6iKcbflGI6fyoYuTmYxeWFjoEjMA2A1+dua6oetWOReBIxF0hNEFAHj55ZexougtIghpQcNtmJdEmj2J5G4jLy+voqLCvSiL5ORkh8dktmBs2bLFveOPPTiB44rlBRi1CIj1SVxv8bLHgwcPHjx48NAiEQqFsrOz/24tPCjDvP7nRaq2ROCsgNbNaVOwurra7/drdzXy4CIAYOTIkatXr7ZcOlfn/xtmkNXV1STV7LERJ/7zn/+88847YkqrVq3caI501RXOOZ7nyxijVVyqoIrno+3YsUNymXj99df1r5KPGjWKcy4eX0twFpkAABUVFbiZ5/f7cZOSOLXcuiWp6piEwDkXb5wRt1FBLTYNhBNlA4EAnQqOuHTpEtjf3bwD/fv3D4VChmHU1tZevnw5MzMTy0h5eTkeMfrWW285M5No4l27di1ZskRyJhs4cKDf78/IyFD0nzNn5OLFi+N5nY7VFDFq1Ch6TkxMzMjIoB1gFe97Uc+CgoI5c+ZIXhN9+vRhDg4QwK3RCRMmFBcXoyuGePzypUuXMMDsoYceApuurQAg3tYnaSaZfsCAAb169bKnulUcnfQFLcFNaOj169c3W+lj7FEYhpGVlUWvx4ggQ7updqJ//PGHJMAsyQGtz+crKSmJxvzss886834W2RzrFg3dunVjTV7qotcS3hKhwhwIBNasWSOWbGhy0gGArKwssYG1DayL0QoC/gZq3O2WdCQ3p0cikfnz52PLppIT0HTNrQgHTlxmWpqEUIqW4mJZdwEgJycHnyORiJMjJzjnsfdj8Qc8+OCDzM7mPhYLy7vdCNeuXTt27Bg+2w0DRsQOZVI0Pbo74/Mvv/yinot0y7Yltm/f3rt3b3x23rqKWnLOqUSoa//RRx81K9ExLLOKHHQdZyT2BeKhJvig7jR7//33W6br6RpGjBhh9naBpiAeSjl//rwGYU3kIrNKu2r5rpQBdvHwww8fOXKkXbt2paWl586dw85S6sslZhWHDF3WiHqD1dq1a6mOi5Vd0Ytk8+bNuu75xsvfCCBM3lVo8W7yefPmiQO9QYMGoX9oKBSKRCJ4UYQ6bty4oTjc+x/8fn84HJ45cyal4J1WLEp0p+KtOYZhLFiwwI2hJkGdVhyp4mB19uzZWVlZP/zwg5guup5WV1fblRIMBg3DeP/997VZwzIqMRgMvvDCC+vWrVNlNwELIN6t7gbUjULOvThWSExMpBhC0SufMYZXLTHG8NJbB0BrmMOBHWL06NHiR2z6JIto8cujs55oGvPEE0/orZqKGYmvNzY2RiIR3HoU+5fp06eLIqZNm8aiX6PaLHDWCMJhMhgD61j5OyCuLuphbELfvn3z8vLca1SZjvUBYpg2bRoIi6sJCQnHjx+nGskY69Spk+MT0wKBwKhRo4LBoPolnRZ48skn8cG9PszVXCQRdl8Rh3JXrlyhnz9x4kT8b3Z2Ng4m9FoGdJ2TZIa4jKv3BitcAhQPDnEJyK8SykPRUmhoXG0WIcrC0h/nj6ISg1OaY8eOgd6rq4irc+fOegsd7VKJhnDvhGAtyl+/fh1MWLx4MQA4u52dgOPKzMxMkVn1Miwzunfvblnu1BGtRLsBXfzFxcXp6ellZWU4EtEVg8FNd5Dp9xnIzs7We4OV3++XNiCZPkNbwu1SooK7ag33brACADzo7vfff9dOTiIQ27dvd0mELkQikV69eoXDYTFAXxvciC9EOD4K3BZacnUUEe28KA8ePHjw8Lfgv20rvlgotqWwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_image(fake_imgs.data[:25], f\"generate_img/{done}.png\", nrow=5, normalize=True)\n",
    "Image(f\"generate_img/{done}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af1538e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_1.1",
   "language": "python",
   "name": "pytorch_1.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
